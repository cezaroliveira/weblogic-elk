input {
 file {
   path => ["/fakelogs/squid.log"]
   sincedb_path => "/dev/null"
   start_position => "beginning"
  }
}

filter {
  # dissect {
  #   mapping => {
  #     "message" => "%{timestamp->} %{duration} %{client_address} %{cache_result}/%{status_code} %{bytes} %{request_method} %{url} %{user} %{hierarchy_code}/%{server} %{content_type}"
  #   }
  #   remove_field => ["message"]
  # }
  grok {
    match => {
      # "message" => "%{NUMBER:timestamp}%{SPACE}%{GREEDYDATA:rest}"
      "message" => "%{NUMBER:timestamp}%{SPACE}%{NUMBER:duration}\s%{IP:client_address}\s%{WORD:cache_result}/%{POSINT:status_code}\s%{NUMBER:bytes}\s%{WORD:request_method}\s%{NOTSPACE:url}\s%{NOTSPACE:user}\s%{WORD:hierarchy_code}/%{NOTSPACE:server}\s%{NOTSPACE:content_type}"
    }
    remove_field => ["message"]
  }
}

output {
  stdout {
    codec => rubydebug { metadata => true }
  }
  elasticsearch {
    # hosts => ["http://localhost:9200"]
    hosts => ["http://elasticsearch:9200"]
    # index => "teste-cezar"
    # Define an indice template to mapping fields to the correct type inside of ElasticSearch
    index => "squid-%{+YYYY.MM.dd}"
    manage_template => true
    template => "/var/lib/logstash/template/squid_mapping.json"
    template_name => "squid_template"
    #user => "elastic"
    #password => "changeme"
  }
}
